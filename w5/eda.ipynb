{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efd316ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a421b8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/ghome/c5mcv04/MCV-C5-2025-Team4/dataset/food_dataset_split/train.csv')  \n",
    "titles = df['Title'].tolist() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0434d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ghome/c5mcv04/miniconda3/envs/rust_env/lib/python3.9/site-packages/spacy/util.py:910: UserWarning: [W095] Model 'en_core_web_lg' (3.8.0) was trained with spaCy v3.8.0 and may not be 100% compatible with the current version (3.7.2). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "food_terms = [\"risotto\", \"pad thai\", \"bulgogi\", \"pho\", \"goulash\",\n",
    "    'chicken', 'beef', 'pork', 'fish', 'shrimp', 'rice', 'pasta', \n",
    "    'tomato', 'onion', 'garlic', 'cheese', 'egg', 'potato', \n",
    "    'carrot', 'broccoli', 'spinach', 'mushroom', 'bell pepper'\n",
    "] \n",
    "for term in food_terms:\n",
    "    lex = nlp.vocab[term]\n",
    "    lex.is_stop = False  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ea881b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_ingredients = [\n",
    "    'chicken', 'beef', 'pork', 'fish', 'shrimp', 'rice', 'pasta', \n",
    "    'tomato', 'onion', 'garlic', 'cheese', 'egg', 'potato', \n",
    "    'carrot', 'broccoli', 'spinach', 'mushroom', 'bell pepper'\n",
    "]\n",
    "\n",
    "common_cuisines = [\n",
    "    'italian', 'mexican', 'chinese', 'japanese', 'indian', \n",
    "    'thai', 'french', 'mediterranean', 'american', 'korean',\n",
    "    'turkish', 'vietnamese'\n",
    "]\n",
    "def extract_ingredients(text):\n",
    "    doc = nlp(text.lower())\n",
    "    ingredients = []\n",
    "    \n",
    "    for token in doc:\n",
    "        # nouns that are likely ingredients\n",
    "        if (token.pos_ in [\"NOUN\", \"PROPN\"] and \n",
    "            not token.is_stop and \n",
    "            len(token.text) > 2):\n",
    "            \n",
    "            # exclude non-ingredient nouns\n",
    "            if not token.text in [\"dinner\", \"lunch\", \"recipe\", \"dish\"]:\n",
    "                ingredients.append(token.text)\n",
    "    \n",
    "    # Handle compound ingredients like \"bell pepper\"\n",
    "    for chunk in doc.noun_chunks:\n",
    "        if any(tok.text in common_ingredients for tok in chunk):\n",
    "            ingredients.append(chunk.text)\n",
    "    \n",
    "    return list(set(ingredients))  \n",
    "\n",
    "def extract_cuisines(text):\n",
    "    doc = nlp(text.lower())\n",
    "    cuisines = []\n",
    "    \n",
    "    # Look for adjectives that might indicate cuisine (Italian, Mexican)\n",
    "    for token in doc:\n",
    "        if token.pos_ == \"PROPN\" and token.text in common_cuisines:\n",
    "            cuisines.append(token.text)\n",
    "    \n",
    "    # Handle cuisine mentions like \"Thai style\"\n",
    "    for i, token in enumerate(doc[:-1]):\n",
    "        next_token = doc[i+1]\n",
    "        if token.text in common_cuisines and next_token.text == \"style\":\n",
    "            cuisines.append(f\"{token.text} {next_token.text}\")\n",
    "    \n",
    "    return list(set(cuisines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab83b6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ingredient_list = []\n",
    "cuisine_list = []\n",
    "\n",
    "for title in titles:\n",
    "    ingredient_list.extend(extract_ingredients(title))\n",
    "    cuisine_list.extend(extract_cuisines(title))\n",
    "\n",
    "# Count occurrences\n",
    "ingredient_counts = Counter(ingredient_list)\n",
    "cuisine_counts = Counter(cuisine_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79e2f3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lemmatized_counts(term_list):\n",
    "    lemmatized_counts = Counter()\n",
    "    for term in term_list:\n",
    "        doc = nlp(term)\n",
    "        # Get base form (lemma) of each word in the term\n",
    "        lemma = \" \".join([token.lemma_ for token in doc])\n",
    "        lemmatized_counts[lemma] += 1\n",
    "    return lemmatized_counts\n",
    "\n",
    "lemmatized_ingredients = get_lemmatized_counts(ingredient_list)\n",
    "lemmatized_cuisines = get_lemmatized_counts(cuisine_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac665974",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_stats_df(counter, total_dishes):\n",
    "    stats = []\n",
    "    for term, count in counter.most_common():\n",
    "        percentage = (count / total_dishes) * 100\n",
    "        if percentage < 0.4:\n",
    "            representation = 'discarded'\n",
    "        elif percentage < 1:\n",
    "            representation = 'underrepresented'\n",
    "        else:\n",
    "            representation = 'common'\n",
    "        stats.append({\n",
    "            'term': term,\n",
    "            'count': count,\n",
    "            'percentage': round((count / total_dishes) * 100, 2),\n",
    "            'representation': representation\n",
    "        })\n",
    "    return pd.DataFrame(stats)\n",
    "\n",
    "total_dishes = len(titles)\n",
    "ingredient_df = create_stats_df(ingredient_counts, total_dishes)\n",
    "cuisine_df = create_stats_df(cuisine_counts, total_dishes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3076da18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Underrepresented Ingredients:\n",
      "            term  count  percentage    representation\n",
      "183        olive     51        0.41  underrepresented\n",
      "179         bars     51        0.41  underrepresented\n",
      "182  goat cheese     51        0.41  underrepresented\n",
      "181       noodle     51        0.41  underrepresented\n",
      "180       citrus     51        0.41  underrepresented\n",
      "..           ...    ...         ...               ...\n",
      "69      rosemary    123        0.98  underrepresented\n",
      "68       mustard    124        0.99  underrepresented\n",
      "67       carrots    124        0.99  underrepresented\n",
      "66     cranberry    125        1.00  underrepresented\n",
      "65         chile    125        1.00  underrepresented\n",
      "\n",
      "[119 rows x 4 columns]\n",
      "\n",
      "Underrepresented Cuisines:\n",
      "Empty DataFrame\n",
      "Columns: [term, count, percentage, representation]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "ingredient_df.to_csv('enhanced_ingredient_analysis_withgenerated.csv', index=False)\n",
    "cuisine_df.to_csv('enhanced_cuisine_analysis_withgenerated.csv', index=False)\n",
    "\n",
    "print(\"Underrepresented Ingredients:\")\n",
    "print(ingredient_df[ingredient_df['representation'] == 'underrepresented'].sort_values('percentage'))\n",
    "\n",
    "print(\"\\nUnderrepresented Cuisines:\")\n",
    "print(cuisine_df[cuisine_df['representation'] == 'underrepresented'].sort_values('percentage'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca1b334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingredients appearing in 0.42% to 1% of dishes:\n",
      "            term  count  percentage    representation\n",
      "59        greens    108        1.00  underrepresented\n",
      "60         style    107        0.99  underrepresented\n",
      "61       spinach    106        0.98  underrepresented\n",
      "62          herb    104        0.97  underrepresented\n",
      "63       sausage    100        0.93  underrepresented\n",
      "..           ...    ...         ...               ...\n",
      "173  goat cheese     46        0.43  underrepresented\n",
      "174      bourbon     46        0.43  underrepresented\n",
      "175      walnuts     46        0.43  underrepresented\n",
      "176       relish     45        0.42  underrepresented\n",
      "177          rib     45        0.42  underrepresented\n",
      "\n",
      "[119 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "ingredient_df = pd.read_csv('enhanced_ingredient_analysis_withgenerated.csv')\n",
    "LOWER_THRESHOLD = 0.42\n",
    "UPPER_THRESHOLD = 1\n",
    "\n",
    "target_ingredients = ingredient_df[\n",
    "    (ingredient_df['percentage'] >= LOWER_THRESHOLD) & \n",
    "    (ingredient_df['percentage'] <= UPPER_THRESHOLD)\n",
    "].sort_values('percentage', ascending=False)\n",
    "\n",
    "print(f\"Ingredients appearing in {LOWER_THRESHOLD}% to {UPPER_THRESHOLD}% of dishes:\")\n",
    "print(target_ingredients)\n",
    "\n",
    "target_ingredients.to_csv('target_ingredients_1_to_0.42_percent.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec01be03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['greens', 'style', 'spinach', 'herb', 'sausage', 'mushrooms', 'ricotta', 'kale', 'chops', 'avocado', 'maple', 'sandwiches', 'strawberry', 'cauliflower', 'goat', 'zucchini', 'vanilla', 'eggplant', 'arugula', 'cucumber', 'vegetables', 'parmesan', 'feta', 'asparagus', 'pot', 'cabbage', 'peanut', 'carrot', 'fruit', 'buttermilk', 'raspberry', 'walnut', 'sugar', 'pear', 'carrots', 'summer', 'sesame', 'ribs', 'basil', 'oil', 'egg', 'peas', 'spice', 'broccoli', 'pecan', 'slaw', 'curry', 'stew', 'glaze', 'mango', 'crust', 'pineapple', 'beet', 'ham', 'pesto', 'olives', 'celery', 'sage', 'crab', 'pizza', 'vegetable', 'baby', 'banana', 'noodles', 'blueberry', 'tacos', 'peppers', 'fish', 'pistachio', 'hazelnut', 'chipotle', 'sandwich', 'miso', 'butternut', 'spring', 'chili', 'thyme', 'herbs', 'ingredient', 'salt', 'dip', 'cheesecake', 'pancakes', 'gravy']\n"
     ]
    }
   ],
   "source": [
    "print(target_ingredients['term'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ccccc59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([ 'spinach', 'herb', 'sausage', 'mushrooms', 'ricotta', 'kale', 'chops', 'avocado', 'maple', 'sandwiches', 'strawberry', 'cauliflower', 'goat', 'zucchini', 'vanilla', 'eggplant', 'arugula', 'cucumber', 'vegetables', 'parmesan', 'feta', 'asparagus', 'cabbage', 'peanut', 'carrot', 'fruit', 'buttermilk', 'raspberry', 'walnut', 'sugar', 'pear', 'carrots', 'sesame', 'ribs', 'basil', 'egg', 'peas', 'spice', 'broccoli', 'pecan', 'curry', 'stew', 'glaze', 'mango', 'pineapple', 'beet', 'ham', 'pesto', 'olives', 'celery', 'sage', 'crab', 'pizza', 'banana', 'noodles', 'blueberry', 'tacos', 'peppers', 'fish', 'pistachio', 'hazelnut', 'chipotle', 'miso', 'butternut', 'chili', 'thyme', 'herbs', 'dip', 'cheesecake', 'pancakes']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c66031e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['greens', 'style', 'spinach', 'herb', 'sausage', 'mushrooms', 'ricotta', 'kale', 'chops', 'avocado', 'maple', 'sandwiches', 'strawberry', 'cauliflower', 'goat', 'zucchini', 'vanilla', 'eggplant', 'arugula', 'cucumber', 'vegetables', 'parmesan', 'feta', 'asparagus', 'pot', 'cabbage', 'peanut', 'carrot', 'fruit', 'buttermilk', 'raspberry', 'walnut', 'sugar', 'pear', 'carrots', 'summer', 'sesame', 'ribs', 'basil', 'oil', 'egg', 'peas', 'spice', 'broccoli', 'pecan', 'slaw', 'curry', 'stew', 'glaze', 'mango', 'crust', 'pineapple', 'beet', 'ham', 'pesto', 'olives', 'celery', 'sage', 'crab', 'pizza', 'vegetable', 'baby', 'banana', 'noodles', 'blueberry', 'tacos', 'peppers', 'fish', 'pistachio', 'hazelnut', 'chipotle', 'sandwich', 'miso', 'butternut', 'spring', 'chili', 'thyme', 'herbs', 'ingredient', 'salt', 'dip', 'cheesecake', 'pancakes', 'gravy', 'steaks', 'wine', 'syrup', 'meatballs', 'cinnamon', 'milk', 'burgers', 'rosemary', 'parsley', 'cakes', 'nut', 'toast', 'pea', 'cheddar', 'dill', 'pan', 'root', 'peach', 'cilantro', 'brussels', 'prosciutto', 'apples', 'bars', 'citrus', 'duck', 'tenderloin', 'cocktail', 'winter', 'spaghetti', 'horseradish', 'goat cheese', 'bourbon', 'walnuts', 'relish', 'rib']\n"
     ]
    }
   ],
   "source": [
    "print(target_ingredients['term'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0dcf051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_ingredients=[ 'spinach', 'herb', 'sausage', 'mushrooms', 'ricotta', 'kale', 'chops', 'avocado', 'maple', 'sandwiches', 'strawberry', 'cauliflower', 'goat', 'zucchini', 'vanilla', 'eggplant', 'arugula', 'cucumber', 'vegetables', 'parmesan', 'feta', 'asparagus', 'cabbage', 'peanut', 'carrot', 'fruit', 'buttermilk', 'raspberry', 'walnut', 'sugar', 'pear', 'carrots', 'sesame', 'ribs', 'basil', 'egg', 'peas', 'spice', 'broccoli', 'pecan', 'curry', 'stew', 'glaze', 'mango', 'pineapple', 'beet', 'ham', 'pesto', 'olives', 'celery', 'sage', 'crab', 'pizza', 'banana', 'noodles', 'blueberry', 'tacos', 'peppers', 'fish', 'pistachio', 'hazelnut', 'chipotle', 'miso', 'butternut', 'chili', 'thyme', 'dip', 'cheesecake', 'pancakes','gravy', 'steaks', 'syrup', 'meatballs', 'milk', 'burgers', 'nut', 'toast', 'pea', 'cheddar', 'peach', 'brussels', 'prosciutto', 'apples', 'duck', 'tenderloin','spaghetti', 'horseradish', 'walnuts', 'rib']\n",
    "len(list_ingredients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3539f285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87\n",
      "['pea', 'cheesecake', 'pear', 'peach', 'glaze', 'raspberry', 'spinach', 'meatballs', 'nut', 'buttermilk', 'strawberry', 'chops', 'apples', 'burgers', 'egg', 'celery', 'ricotta', 'cauliflower', 'sugar', 'avocado', 'spaghetti', 'gravy', 'crab', 'brussels', 'feta', 'asparagus', 'herb', 'pancakes', 'peppers', 'sandwiches', 'sausage', 'dip', 'curry', 'horseradish', 'ham', 'mango', 'pizza', 'maple', 'carrot', 'hazelnut', 'ribs', 'rib', 'miso', 'goat', 'olives', 'vegetables', 'broccoli', 'duck', 'prosciutto', 'fish', 'peas', 'chipotle', 'sesame', 'zucchini', 'spice', 'kale', 'syrup', 'chili', 'walnut', 'eggplant', 'tenderloin', 'pineapple', 'sage', 'banana', 'cucumber', 'peanut', 'toast', 'arugula', 'cheddar', 'stew', 'tacos', 'vanilla', 'noodles', 'mushrooms', 'pesto', 'steaks', 'milk', 'beet', 'blueberry', 'butternut', 'basil', 'parmesan', 'thyme', 'fruit', 'pecan', 'pistachio', 'cabbage']\n"
     ]
    }
   ],
   "source": [
    "def remove_plural_duplicates(ingredients):\n",
    "    cleaned = set()\n",
    "    for item in ingredients:\n",
    "        singular = item.rstrip('s') if item.endswith('s') else item\n",
    "        # Solo agregamos el plural si no existe la forma singular\n",
    "        if singular not in cleaned:\n",
    "            cleaned.add(item)\n",
    "    return list(cleaned)\n",
    "\n",
    "\n",
    "cleaned_items = remove_plural_duplicates(list_ingredients)\n",
    "print(len(cleaned_items))\n",
    "print(cleaned_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62f78d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Representation analysis Before Generation:\n",
      "Total items processed: 5716\n",
      "Total count: 38,007\n",
      "\n",
      "Percentage of total counts by representation category:\n",
      "Discarded      : 46.42% (17,644/38,007)\n",
      "Underrepresented: 21.83% (8,296/38,007)\n",
      "Common         : 31.75% (12,067/38,007)\n",
      "\n",
      "Top items by category:\n",
      "\n",
      "Common (top 3):\n",
      "  salad          : 788 (7.32%)\n",
      "  chicken        : 698 (6.48%)\n",
      "  sauce          : 549 (5.10%)\n",
      "\n",
      "Underrepresented (top 3):\n",
      "  style          : 107 (0.99%)\n",
      "  spinach        : 106 (0.98%)\n",
      "  herb           : 104 (0.97%)\n",
      "\n",
      "Discarded (top 3):\n",
      "  quinoa         : 42 (0.39%)\n",
      "  verde          : 42 (0.39%)\n",
      "  watermelon     : 42 (0.39%)\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from collections import Counter\n",
    "\n",
    "# Path to your CSV file\n",
    "csv_path = \"/ghome/c5mcv04/MCV-C5-2025-Team4/w5/enhanced_ingredient_analysis.csv\"  # Change this to your actual filename\n",
    "\n",
    "# Read data from CSV\n",
    "items = []\n",
    "with open(csv_path, 'r', newline='') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)  # Using DictReader to handle columns by name\n",
    "    for row in reader:\n",
    "        try:\n",
    "            term = row['term'].strip()\n",
    "            count = int(row['count'])\n",
    "            percentage = float(row['percentage'])\n",
    "            # We'll calculate representation ourselves, ignoring the CSV's representation column\n",
    "            items.append((term, count, percentage))\n",
    "        except (ValueError, KeyError):\n",
    "            continue  # Skip rows with missing/malformed data\n",
    "\n",
    "if not items:\n",
    "    print(\"No valid items found in the CSV file.\")\n",
    "    exit()\n",
    "\n",
    "# Total count across all items\n",
    "total_count = sum(count for _, count, _ in items)\n",
    "\n",
    "if total_count == 0:\n",
    "    print(\"Total count is zero - cannot calculate category sums.\")\n",
    "    exit()\n",
    "\n",
    "# Category-wise sum of counts\n",
    "representation_sums = defaultdict(int)\n",
    "\n",
    "# Classify and sum based on percentage values\n",
    "for term, count, percentage in items:\n",
    "    if percentage < 0.40:\n",
    "        category = 'discarded'\n",
    "    elif percentage < 1:\n",
    "        category = 'underrepresented'\n",
    "    else:\n",
    "        category = 'common'\n",
    "    representation_sums[category] += count\n",
    "\n",
    "# Display final results\n",
    "print(\"\\nRepresentation analysis Before Generation:\")\n",
    "print(f\"Total items processed: {len(items)}\")\n",
    "print(f\"Total count: {total_count:,}\\n\")\n",
    "\n",
    "print(\"Percentage of total counts by representation category:\")\n",
    "for category in ['discarded', 'underrepresented', 'common']:\n",
    "    category_sum = representation_sums.get(category, 0)\n",
    "    pct_of_total = (category_sum / total_count) * 100\n",
    "    print(f\"{category.capitalize():<15}: {pct_of_total:.2f}% ({category_sum:,}/{total_count:,})\")\n",
    "\n",
    "# Bonus: Show top 3 items in each category\n",
    "print(\"\\nTop items by category:\")\n",
    "category_items = {'discarded': [], 'underrepresented': [], 'common': []}\n",
    "for term, count, percentage in items:\n",
    "    if percentage < 0.40:\n",
    "        category_items['discarded'].append((term, count, percentage))\n",
    "    elif percentage < 1:\n",
    "        category_items['underrepresented'].append((term, count, percentage))\n",
    "    else:\n",
    "        category_items['common'].append((term, count, percentage))\n",
    "\n",
    "for category in ['common', 'underrepresented', 'discarded']:\n",
    "    print(f\"\\n{category.capitalize()} (top 3):\")\n",
    "    sorted_items = sorted(category_items[category], key=lambda x: x[1], reverse=True)[:3]\n",
    "    for term, count, percentage in sorted_items:\n",
    "        print(f\"  {term:<15}: {count:,} ({percentage:.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5288a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Representation analysis after Generation:\n",
      "Total items processed: 6055\n",
      "Total count: 44,918\n",
      "\n",
      "Percentage of total counts by representation category:\n",
      "Discarded      : 44.09% (19,805/44,918)\n",
      "Underrepresented: 21.37% (9,600/44,918)\n",
      "Common         : 34.54% (15,513/44,918)\n",
      "\n",
      "Top items by category:\n",
      "\n",
      "Common (top 3):\n",
      "  salad          : 1,016 (8.12%)\n",
      "  chicken        : 867 (6.93%)\n",
      "  sauce          : 684 (5.47%)\n",
      "\n",
      "Underrepresented (top 3):\n",
      "  carrots        : 124 (0.99%)\n",
      "  mustard        : 124 (0.99%)\n",
      "  rosemary       : 123 (0.98%)\n",
      "\n",
      "Discarded (top 3):\n",
      "  apples         : 49 (0.39%)\n",
      "  tofu           : 49 (0.39%)\n",
      "  barbecue       : 48 (0.38%)\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "# Path to your CSV file\n",
    "csv_path = \"/ghome/c5mcv04/MCV-C5-2025-Team4/w5/enhanced_ingredient_analysis_withgenerated.csv\"  # Change this to your actual filename\n",
    "\n",
    "# Read data from CSV\n",
    "items = []\n",
    "with open(csv_path, 'r', newline='') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)  # Using DictReader to handle columns by name\n",
    "    for row in reader:\n",
    "        try:\n",
    "            term = row['term'].strip()\n",
    "            count = int(row['count'])\n",
    "            percentage = float(row['percentage'])\n",
    "            # We'll calculate representation ourselves, ignoring the CSV's representation column\n",
    "            items.append((term, count, percentage))\n",
    "        except (ValueError, KeyError):\n",
    "            continue  # Skip rows with missing/malformed data\n",
    "\n",
    "if not items:\n",
    "    print(\"No valid items found in the CSV file.\")\n",
    "    exit()\n",
    "\n",
    "# Total count across all items\n",
    "total_count = sum(count for _, count, _ in items)\n",
    "\n",
    "if total_count == 0:\n",
    "    print(\"Total count is zero - cannot calculate category sums.\")\n",
    "    exit()\n",
    "\n",
    "# Category-wise sum of counts\n",
    "representation_sums = defaultdict(int)\n",
    "\n",
    "# Classify and sum based on percentage values\n",
    "for term, count, percentage in items:\n",
    "    if percentage < 0.40:\n",
    "        category = 'discarded'\n",
    "    elif percentage < 1:\n",
    "        category = 'underrepresented'\n",
    "    else:\n",
    "        category = 'common'\n",
    "    representation_sums[category] += count\n",
    "\n",
    "# Display final results\n",
    "print(\"\\nRepresentation analysis after Generation:\")\n",
    "print(f\"Total items processed: {len(items)}\")\n",
    "print(f\"Total count: {total_count:,}\\n\")\n",
    "\n",
    "print(\"Percentage of total counts by representation category:\")\n",
    "for category in ['discarded', 'underrepresented', 'common']:\n",
    "    category_sum = representation_sums.get(category, 0)\n",
    "    pct_of_total = (category_sum / total_count) * 100\n",
    "    print(f\"{category.capitalize():<15}: {pct_of_total:.2f}% ({category_sum:,}/{total_count:,})\")\n",
    "\n",
    "# Bonus: Show top 3 items in each category\n",
    "print(\"\\nTop items by category:\")\n",
    "category_items = {'discarded': [], 'underrepresented': [], 'common': []}\n",
    "for term, count, percentage in items:\n",
    "    if percentage < 0.40:\n",
    "        category_items['discarded'].append((term, count, percentage))\n",
    "    elif percentage < 1:\n",
    "        category_items['underrepresented'].append((term, count, percentage))\n",
    "    else:\n",
    "        category_items['common'].append((term, count, percentage))\n",
    "\n",
    "for category in ['common', 'underrepresented', 'discarded']:\n",
    "    print(f\"\\n{category.capitalize()} (top 3):\")\n",
    "    sorted_items = sorted(category_items[category], key=lambda x: x[1], reverse=True)[:3]\n",
    "    for term, count, percentage in sorted_items:\n",
    "        print(f\"  {term:<15}: {count:,} ({percentage:.2f}%)\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spacy_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
